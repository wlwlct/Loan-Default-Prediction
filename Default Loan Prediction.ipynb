{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "Predict whether the accepted loan would be properly paid back or not\n",
    "\n",
    "log:\n",
    "drop columns and load all data\n",
    "move on to feature engineering\n",
    "\n",
    "\n",
    "Make it better:\n",
    "Can we use forward and backward or stepwise method to select the important parameter?\n",
    "\n",
    "Should we treat ordinal value as catagory values or numeric values?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from datetime import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = pd.read_csv('accepted_2007_to_2018q4.csv/accepted_2007_to_2018Q4.csv', chunksize=10000)\n",
    "mid=[]\n",
    "for chunk in reader:\n",
    "    chunk=chunk[chunk['loan_status'].apply( lambda x: x not in ['Does not meet the credit policy. Status:Fully Paid', 'Does not meet the credit policy. Status:Charged Off'])]\n",
    "    # drop columns with more than 50% missing values\n",
    "    chunk.rename(columns={'verification_status_joint':'verified_status_joint'}, inplace=True)\n",
    "\n",
    "    chunk = chunk.drop(columns= ['verified_status_joint','sec_app_mths_since_last_major_derog', 'sec_app_revol_util',\n",
    "       'revol_bal_joint', 'sec_app_inq_last_6mths',\n",
    "       'sec_app_collections_12_mths_ex_med',\n",
    "       'sec_app_chargeoff_within_12_mths', 'sec_app_num_rev_accts',\n",
    "       'sec_app_open_acc', 'sec_app_mort_acc', 'sec_app_fico_range_high',\n",
    "       'sec_app_fico_range_low', 'dti_joint', 'annual_inc_joint',\n",
    "       'mths_since_last_record', 'mths_since_recent_bc_dlq',\n",
    "       'mths_since_last_major_derog', 'mths_since_recent_revol_delinq',\n",
    "       'mths_since_last_delinq'])\n",
    "\n",
    "    #  drop columns with more than 20% of missing values\n",
    "    chunk = chunk.drop(columns=['open_acc_6m', 'open_il_12m', 'open_il_24m', 'mths_since_rcnt_il',\n",
    "       'total_bal_il', 'il_util', 'open_rv_12m', 'open_rv_24m', 'max_bal_bc',\n",
    "       'all_util', 'inq_fi', 'total_cu_tl', 'inq_last_12m'])\n",
    "\n",
    "    # drop column without explaination\n",
    "    chunk = chunk.drop(columns=['debt_settlement_flag', 'debt_settlement_flag_date', 'deferral_term',\\\n",
    "         'disbursement_method', 'hardship_amount', 'hardship_dpd', 'hardship_end_date', 'hardship_flag',\\\n",
    "            'hardship_last_payment_amount', 'hardship_length', 'hardship_loan_status', 'hardship_payoff_balance_amount', \\\n",
    "            'hardship_reason', 'hardship_start_date', 'hardship_status', 'hardship_type', 'open_act_il', \\\n",
    "            'orig_projected_additional_accrued_interest', 'payment_plan_start_date', 'sec_app_open_act_il',\\\n",
    "            'settlement_amount', 'settlement_date', 'settlement_percentage', 'settlement_status', 'settlement_term'])\n",
    "    # drop column with high correlation\n",
    "    chunk = chunk.drop(columns=['out_prncp_inv','funded_amnt','funded_amnt_inv','tot_hi_cred_lim','total_il_high_credit_limit'])\n",
    "    # columns that are not related to prediction\n",
    "    chunk = chunk.drop(columns=['url','desc','member_id','id','emp_title','sub_grade','zip_code','policy_code'])\n",
    "\n",
    "    # drop column with date\n",
    "    chunk = chunk.drop(columns= ['issue_d','earliest_cr_line','last_pymnt_d','next_pymnt_d','last_credit_pull_d','sec_app_earliest_cr_line'])\n",
    "\n",
    "    mid.append(chunk)\n",
    "\n",
    "accepted = pd.concat(mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description from dataset:\n",
    "data_descriptions = pd.read_excel('LCDataDictionary.xlsx', sheet_name=[0,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the following, we will try to analysis the column information and remvovee non-related columns. To do this, our first step is to understand the meaning of each column. The data set is acompanied with a well-documented data description. We will use it as a guideline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove columns that are not well defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_descriptions[0] = data_descriptions[0][['LoanStatNew', 'Description']]\n",
    "data_descriptions[1].columns =['LoanStatNew', 'Description']\n",
    "data_descriptions = pd.concat([data_descriptions[0], data_descriptions[1]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clearly there is an extra space need to be dealt with.\n",
    "data_descriptions.LoanStatNew = data_descriptions.LoanStatNew.str.strip()\n",
    "# verified status joint is called verification status joint in the dataset\n",
    "accepted.rename(columns={'sverification_status_joint':'verified_status_joint'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_descriptions = data_descriptions[[pd.notna(i) for i in data_descriptions.LoanStatNew]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which column does not have an description\n",
    "print('column name in data without description')\n",
    "print(sorted(set(accepted.columns)-set(data_descriptions.LoanStatNew)))\n",
    "print('*'*100)\n",
    "print(sorted(set(data_descriptions.LoanStatNew)-set(accepted.columns)  ))\n",
    "# The columns which does not contain a proper description will be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that do not have a proper explaination\n",
    "accepted.drop(columns=list(set(accepted.columns)-set(data_descriptions.LoanStatNew)), inplace=True)\n",
    "accepted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general examine data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earliest_cr_line, last_pymnt_d, next_pymnt_d, last_credit_pull_d suppose to be datetime month_label-Year\n",
    "#for col in ['earliest_cr_line', 'last_pymnt_d', 'next_pymnt_d', 'last_credit_pull_d','issue_d','sec_app_earliest_cr_line']:\n",
    "#    accepted[col] = pd.to_datetime(accepted[col], format='%b-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert id into object\n",
    "#accepted[['id','policy_code']]=accepted[['id','policy_code']].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dtypes\n",
    "accepted.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int\n",
    "accepted.select_dtypes('int64').columns # id should be cat value\n",
    "# <M8[ns]\n",
    "datetime_dict={col: [ accepted[col].unique()] for col in accepted.select_dtypes('<M8[ns]').columns}\n",
    "# float\n",
    "float_dict={col: [ accepted[col].unique()] for col in accepted.select_dtypes('float64').columns}\n",
    "# 0\n",
    "object_dict={col: [accepted[col].unique()] for col in accepted.select_dtypes('O').columns}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unique datetime\n",
    "would not necessary for prediction\n",
    "\n",
    "potential: time interval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique datetime\n",
    "pd.DataFrame.from_dict(datetime_dict, orient='index').rename(columns={0:'unique_values'})\n",
    "date_col = ['issue_d','earliest_cr_line','last_pymnt_d','next_pymnt_d','last_credit_pull_d','sec_app_earliest_cr_line']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unique object values\n",
    "- identify columns that are not necessary: \n",
    "id, url, zip_code, grade/subgrade, title?, emp_title?\n",
    "\n",
    "\n",
    "- test whether data type is proper or not\n",
    "- define values for prediction\n",
    "- clean nan values\n",
    "- chisq independent test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique object values\n",
    "object_dict_unique = pd.DataFrame.from_dict(object_dict, orient='index').rename(columns={0:'unique_values'})\n",
    "object_dict_unique['n']=object_dict_unique['unique_values'].apply(len)\n",
    "object_dict_unique.sort_values(\"n\")\n",
    "# not related columns: id, url, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted['title'].str.lower().str.replace(' loan','').str.contains('loan').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words1=['just','a','the','my','need','help','to', 'one', 'me', 'for','smart', 'jc', 'low', 'looking', 'lower', 'mike\\'s', 'mike',\\\n",
    "    'michelle\\'s', 'michelle', 'many', 'needed', 'mission', 'dad\\'s', 'seeking', 'high', 'it', 'new', 'nice', 'and','quick','next','level', 'more',\\\n",
    "        'large','small','lendingclub','better', 'me', 'you','beautiful','easy', 'finally', 'rescue', 'get','first','last','second', 'up','lower',\\\n",
    "            'combine','little', 'project','please', 'thank', 'thanks','ny','of','is','are','i','on','&','this','in','me,','be','with','from','-',\\\n",
    "                'big','short','end','our', 'needs', 'bye','two','over','will','at','some','do','clear','combine','no','or']\n",
    "accepted['title'] = accepted['title'].apply( lambda x: ' '.join([s for s in x.split() if (s not in stop_words1)]) if pd.notna(x) else x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### value recode\n",
    "stop_words2=['lending club','no more','-','\\s','\\d','$','best','better','big','bye','final','buy','finish','going','good','great','hard','high',\\\n",
    "    'happy','honest','less','than','responsible','rich','right','short','long','smart','smile','term','want','unexpected','the','project','new','mine',\n",
    "    'profit','first','second','expense']\n",
    "accepted['title'] = accepted['title'].str.lower().str.replace(' loan','').str.replace('loan ','').str.strip('!,\\'-.?&#$\\/\\ \\\\0123456789%:+=\\\"_)(')\n",
    "accepted['title'] = accepted['title'].str.replace('c.c.','credit card')\n",
    "accepted['title'] = accepted['title'].str.replace('lc','lending club')\n",
    "accepted['title'] = accepted['title'].str.replace('cc','credit card')\n",
    "\n",
    "for word in stop_words2:\n",
    "    accepted['title'] = accepted['title'].str.replace(word,'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### grade and subgrade, if grade is empty, subgrade is empty\n",
    "#accepted[['grade', 'sub_grade']].isna().sum(axis=1).unique()\n",
    "#### moving is basically physically moving\n",
    "accepted['title'][accepted['title'].apply(lambda x: 'moving' in x if pd.notna(x) else False)]\n",
    "#### mustang is car\n",
    "accepted['title'][accepted['title'].apply(lambda x: 'mustang' in x if pd.notna(x) else False)]\n",
    "#### banks means people dont like the idea of bank\n",
    "accepted['title'][accepted['title'].apply(lambda x: 'banks' in x if pd.notna(x) else False)]\n",
    "#### mediacal is medial expanse\n",
    "accepted['title'][accepted['title'].apply(lambda x: 'med' in x if pd.notna(x) else False)]\n",
    "#### mba is school\n",
    "accepted['title'][accepted['title'].apply(lambda x: 'mba' in x if pd.notna(x) else False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted['title'][accepted['title'].apply(lambda x: 'wash' in x if pd.notna(x) else False)].value_counts().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reword={'debt':['deb','debt','dedt','dbt','dept','bill','debit','wells','chase','citi','visa','bankamerica','bankofamerica','barclay','amex','american','boa','bofa','credit card',\\\n",
    "        'creditcard','credit','card','pay','pay-off','payoff','pay off','off','payback','paid','discover'],\\\n",
    "    'consolidation':['consolidation','con','cos','capitolslate','consalidadtion','conso','reconciliation','consoildation','consolidation','consolodation',\\\n",
    "        'consoldate','consolitation','consolidate','consol','cosolidation','onsolidation','recon','consol','refinance','refi','re-fi'],\\\n",
    "    'medical':['med','hospital','dental','health','surgery','dentist','rehab','headache','doctor'],\\\n",
    "    'wedding':['diamondring','wed','engage','honey','wedding','engagement','marr','ring'],\\\n",
    "    'mbuy':['mus','major','equip','daniel','defense','appliance','computer','laptop','camera','purchase','perchase','porchase',\\\n",
    "        'golf','boat','purchase','gun','software','seadoo','ship'],\\\n",
    "    'vehicle':['motor','dodge','harley','kawa','chevy','bmw','ford','toyota','wheels','honda','scooter','vehic','truck','mustang','subaru','suzuki',\n",
    "        'mazda','auto','mercedes','auto','fuel','car','transmission','jeep','bike','trailer','subaru','nissan','engine','volvo','truck'],\\\n",
    "    'emergency':['emer','emr','emergency'],\\\n",
    "    'moving':['crossc','relo','moving','move'],\\\n",
    "    'law':['legal','attorney','law'],\\\n",
    "    'school':['edu','exam','training','classes','school','mba','mster\\'s','student','graduate','phd','education','course','tuition','book','college',\n",
    "        'teacher','program'], \n",
    "    'business':['farm','invent','business','buiness','buis','bus','bakery','shop','studio','web','buisness','company','busines','start-up',\n",
    "        'startup','start up','inves'],\\\n",
    "    'home':['hous','heat','condo','chimney','apart','build','barn','basement','bassment','bath','boil','borrow',\\\n",
    "        'driveway','sewer','solar','property','cabin','yard','office','lawn','basement','renovat','home','mortgage','tub','pool','roof','rent',\\\n",
    "        'garage','bathroom','bedroom','kitchen','outdoor','suite','room','floor','ceil','garden','house','window','deck','fence','remodel','a/c','furniture','bed',\n",
    "        'furnace','landscape','shelter','remo','tree','wash','lighttunnel'],\\\n",
    "    'personal':['presonal','pesonel','priv','peronal','personnel','personal','person','personal','vacation','money','cash','trip','pers','pes'],\\\n",
    "    'family':['child','adop','brother','sister','baby','mom','father','mother','grand','dad','daughter','kid','fam','funeral','myson'],\\\n",
    "    'other':['making','catch','eas','chan','fix','hop','impr','clear','com','never','add','bad','break','bright','help',\\\n",
    "        'bridge','sum','bless','blue','back','balan','insurance','together','all','goal','god','no','temp','self','free',\\\n",
    "        'live','lend','start','breath','day','clean','dream','love','peace','jan','feb','march','april','may','june','july',\\\n",
    "        'august','september','october','november','december','financ','redu','stres','soul','luck','month','opera','reduce',\\\n",
    "        'spring','time','out','plan','clos','capi','life','begin','mistake','sav','relief','air','tax','apr','interest','banks','green','vaction','simp']\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in reword.items():\n",
    "    for item in v:\n",
    "        accepted['title']=accepted['title'].apply(lambda x: (k if item in x else x) if isinstance(x,str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted['title'] = accepted['title'].replace({'or':'other','loan':'other','':'other','myloan':'other','future':'other','s':'other','k':'other',\n",
    "'my':'other'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = accepted[['title']].value_counts()\n",
    "plt.plot(range(len(test)), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10_index = [col[0] for col in accepted[['title']].value_counts().iloc[:10].index]\n",
    "accepted['title'] = accepted['title'].apply(lambda x: (x if x in top10_index else 'other') if isinstance(x,str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### title, emp_title\n",
    "accepted[['title']].value_counts().head(20)\n",
    "#[test.append(i[0].split()) if isinstance(i[0].split(),str) else test.extend(i[0].split()) for i in accepted[['title']].value_counts().keys()]\n",
    "#from collections import Counter\n",
    "#sorted(Counter(test).items(), key=lambda x: x[1], reverse=True)\n",
    "#sorted(Counter(test).items(), key=lambda x: x[0])[6000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### emp title 436961 unique\n",
    "#len(accepted['emp_title'].str.lower().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_related_cols = ['id','emp_title','sub_grade','zip_code','policy_code']\n",
    "object_dict_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### define loan status value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Column Explaination**\n",
    "\n",
    "revolving loan: A revolving loan facility is a form of credit issued by a financial institution that provides the borrower with the ability to draw down or withdraw, repay, and withdraw again. A revolving loan is considered a flexible financing tool due to its repayment and re-borrowing accommodations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loan status explaination**\n",
    "\n",
    "Current: Loan is up to date on all outstanding payments. / any loan that is fully paid to date according to a contract.\n",
    "\n",
    "Fully paid: Loan has been fully repaid, either at the expiration of the 3- or 5-year year term or as a result of a prepayment.\n",
    " \n",
    " \n",
    "In Grace Period: Loan is past due but within the 15-day grace period. \n",
    " \n",
    "Late (16-30): Loan has not been current for 16 to 30 days. Learn more about the tools LendingClub has to deal with delinquent borrowers.\n",
    " \n",
    "Late (31-120): Loan has not been current for 31 to 120 days. Learn more about the tools LendingClub has to deal with delinquent borrowers.\n",
    " \n",
    "Default: Loan has not been current for an extended period of time. \n",
    "\n",
    "Charged Off: Loan for which there is no longer a reasonable expectation of further payments. Upon Charge Off, the remaining principal balance of the Note is deducted from the account balance.\n",
    "\n",
    "Default and charged-off:\n",
    "About 4-6 months after you miss your first payment, your loan will default and then charge-off. \n",
    "\n",
    "**From the defination above, charged off and default would be treated as default**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unique value counts\n",
    "accepted['loan_status'].value_counts()\n",
    "# From the table bellow, does not meet the credit policy would be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remvove nan\n",
    "accepted.dropna(subset=['loan_status'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted['Default']=accepted['loan_status'].apply(lambda x: 1 if x in ['Default', 'Charged Off'] else 0).astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted[object_dict_unique.index].isnull().mean()*100\n",
    "# drop verified_status_joint has more than 94 percent of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accepted.drop(columns='loan_status', inplace=True)\n",
    "accepted['emp_length']=accepted['emp_length'].fillna(accepted['emp_length'].mode()[0])\n",
    "accepted['title']=accepted['title'].fillna(accepted['title'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unique numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique numeric values\n",
    "float_dict_unique=pd.DataFrame.from_dict(float_dict, orient='index').rename(columns={0:'unique_values'})\n",
    "float_dict_unique['n']=float_dict_unique['unique_values'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find column with single value\n",
    "float_dict_unique[float_dict_unique['n']==1].index\n",
    "# single value: 'member_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find column with less than 10% of unique values. (1000 for 10000)\n",
    "unique_index_1000=float_dict_unique[float_dict_unique['n']>1000].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display all columns\n",
    "single_value_index=[]\n",
    "\n",
    "numeric_cols=float_dict_unique.drop(index=single_value_index)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(numeric_cols.sort_values('n'))\n",
    "\n",
    "# policy_code is cat value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentage of 0s\n",
    "float_zeros = pd.DataFrame((accepted[float_dict_unique.index]==0).mean())\n",
    "float_zeros.columns=['percentage of 0s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all missing values\n",
    "accepted.isnull().any(axis=1).sum()/2257952 # 0.9998609359277788 not possible to remove all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  remove columns with missing  values more than 50%\n",
    "float_dict_missing = accepted[float_dict_unique.index].isnull().mean()*100\n",
    "float_dict_missing = float_dict_unique.join(float_dict_missing.rename('missing percentage'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of misssing\n",
    "float_dict_missing['missing percentage'].sort_values().plot(kind='bar')\n",
    "plt.ylabel('percentage of missing values')\n",
    "plt.xlabel('column names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_dict_missing[float_dict_missing['missing percentage']>20].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  check the number of rows with full set of data\n",
    "accepted[float_dict_missing.index].isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    def df_unique_missing_0s(df):\n",
    "    numeric_cols=float_dict_unique.drop(index=single_value_index)\n",
    "    # percentage of 0s\n",
    "    float_zeros = pd.DataFrame((df[float_dict_unique.index]==0).mean())\n",
    "    float_zeros.columns=['percentage of 0s']\n",
    "    # missings\n",
    "    float_dict_missing = df[float_dict_unique.index].isnull().mean()*100\n",
    "    float_dict_missing = float_dict_unique.join(float_dict_missing.rename('missing percentage'))\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        display(numeric_cols.join(float_zeros).join(float_dict_missing['missing percentage']).\\\n",
    "        sort_values(['missing percentage','percentage of 0s'], ascending=False))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accepted_trimed=accepted.drop(columns='mths_since_recent_inq').dropna()\n",
    "# could not use trimed version because it significantly remove default data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(numeric_cols.join(float_zeros).join(float_dict_missing['missing percentage']).\\\n",
    "        sort_values(['missing percentage','percentage of 0s'], ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the correlation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted['Default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the correlation of the column that contains numeric values\n",
    "accepted_numeric_corr = accepted[unique_index_1000].drop(columns=['recoveries','collection_recovery_fee']).corr()\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(accepted_numeric_corr,vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_numeric_corr_melt = accepted_numeric_corr.reset_index(drop=False).melt('index', var_name='var2', value_name='corr')\n",
    "accepted_numeric_corr_melt = accepted_numeric_corr_melt.rename(columns={'index':'var1'})\n",
    "highly_corr_cols = accepted_numeric_corr_melt[(abs(accepted_numeric_corr_melt['corr'])>0.8) & (accepted_numeric_corr_melt['var1']!=accepted_numeric_corr_melt['var2'])]\n",
    "highly_corr_cols['combine'] = (highly_corr_cols['var1']+highly_corr_cols['var2']).apply(lambda x: ''.join(sorted(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    highly_corr_cols=highly_corr_cols.sort_values('corr', ascending=False).drop_duplicates(subset='combine')\n",
    "    display(highly_corr_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v1,v2 in highly_corr_cols[['var1','var2']].values:\n",
    "    print(v1,v2)\n",
    "    plt.figure()\n",
    "    #plt.scatter(accepted[v1], accepted[[v1,v2]].groupby(v1).mean().reset_index()[v2])\n",
    "    accepted[[v1,v2]].groupby(v1).mean().reset_index().plot(kind='scatter', x=v1,y=v2)\n",
    "    plt.show()\n",
    "# drop on in:\n",
    "# out_prncp/out_prncp_inv; funded_amnt/loan_amnt; loan_amnt/funded_amnt_inv; tot_cur_bal/tot_hi_cred_lim;\n",
    "# total_il_high_credit_limit/total_bal_ex_mort; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_prncp/out_prncp_inv; tot_cur_bal/tot_hi_cred_lim;\n",
    "# total_il_high_credit_limit/total_bal_ex_mort; \n",
    "high_corr_cols = ['out_prncp_inv','funded_amnt','funded_amnt_inv','tot_hi_cred_lim','total_il_high_credit_limit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**delinquent**: Delinquency means that you are behind on payments. Once you are delinquent for a certain period of time (usually nine months for federal loans), your lender will declare the loan to be in default. The entire loan balance will become due at that time.\n",
    "\n",
    "**trades**: Trade finance represents the financial instruments and products that are used by companies to facilitate international trade and commerce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fill missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_dict_missing[float_dict_missing['missing percentage']>0].sort_values('n', ascending=False)\n",
    "# below 20 use mode, above 20 use median\n",
    "for col in float_dict_missing.index:\n",
    "    if float_dict_missing.loc[col,'n']>20:\n",
    "        accepted[col].fillna(accepted[col].median(),inplace=True)\n",
    "    else:\n",
    "        accepted[col].fillna(accepted[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(pd.DataFrame(accepted.isnull().mean()).sort_values(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>installment</th>\n",
       "      <th>grade</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>...</th>\n",
       "      <th>num_tl_120dpd_2m</th>\n",
       "      <th>num_tl_30dpd</th>\n",
       "      <th>num_tl_90g_dpd_24m</th>\n",
       "      <th>num_tl_op_past_12m</th>\n",
       "      <th>pct_tl_nvr_dlq</th>\n",
       "      <th>percent_bc_gt_75</th>\n",
       "      <th>pub_rec_bankruptcies</th>\n",
       "      <th>tax_liens</th>\n",
       "      <th>total_bal_ex_mort</th>\n",
       "      <th>total_bc_limit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>13.99</td>\n",
       "      <td>123.03</td>\n",
       "      <td>C</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>76.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7746.0</td>\n",
       "      <td>2400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24700.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>11.99</td>\n",
       "      <td>820.28</td>\n",
       "      <td>C</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97.4</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39475.0</td>\n",
       "      <td>79300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>10.78</td>\n",
       "      <td>432.66</td>\n",
       "      <td>B</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18696.0</td>\n",
       "      <td>6200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>14.85</td>\n",
       "      <td>829.90</td>\n",
       "      <td>C</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52226.0</td>\n",
       "      <td>62500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10400.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>22.45</td>\n",
       "      <td>289.91</td>\n",
       "      <td>F</td>\n",
       "      <td>3 years</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>104433.0</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>96.6</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95768.0</td>\n",
       "      <td>20300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amnt        term  int_rate  installment grade emp_length  \\\n",
       "0     3600.0   36 months     13.99       123.03     C  10+ years   \n",
       "1    24700.0   36 months     11.99       820.28     C  10+ years   \n",
       "2    20000.0   60 months     10.78       432.66     B  10+ years   \n",
       "3    35000.0   60 months     14.85       829.90     C  10+ years   \n",
       "4    10400.0   60 months     22.45       289.91     F    3 years   \n",
       "\n",
       "  home_ownership  annual_inc verification_status loan_status  ...  \\\n",
       "0       MORTGAGE     55000.0        Not Verified           0  ...   \n",
       "1       MORTGAGE     65000.0        Not Verified           0  ...   \n",
       "2       MORTGAGE     63000.0        Not Verified           0  ...   \n",
       "3       MORTGAGE    110000.0     Source Verified           0  ...   \n",
       "4       MORTGAGE    104433.0     Source Verified           0  ...   \n",
       "\n",
       "  num_tl_120dpd_2m num_tl_30dpd num_tl_90g_dpd_24m num_tl_op_past_12m  \\\n",
       "0              0.0          0.0                0.0                3.0   \n",
       "1              0.0          0.0                0.0                2.0   \n",
       "2              0.0          0.0                0.0                0.0   \n",
       "3              0.0          0.0                0.0                1.0   \n",
       "4              0.0          0.0                0.0                4.0   \n",
       "\n",
       "   pct_tl_nvr_dlq  percent_bc_gt_75  pub_rec_bankruptcies  tax_liens  \\\n",
       "0            76.9               0.0                   0.0        0.0   \n",
       "1            97.4               7.7                   0.0        0.0   \n",
       "2           100.0              50.0                   0.0        0.0   \n",
       "3           100.0               0.0                   0.0        0.0   \n",
       "4            96.6              60.0                   0.0        0.0   \n",
       "\n",
       "   total_bal_ex_mort  total_bc_limit  \n",
       "0             7746.0          2400.0  \n",
       "1            39475.0         79300.0  \n",
       "2            18696.0          6200.0  \n",
       "3            52226.0         62500.0  \n",
       "4            95768.0         20300.0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cleaned dataset\n",
    "accepted_cleaned = pd.read_csv('./cleaned dataset.csv',dtype={'loan_status':'O'})\n",
    "accepted_cleaned.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "accepted_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of the of each type\n",
    "for col in accepted_cleaned.select_dtypes('object').columns:\n",
    "    sns.countplot(accepted_cleaned[col])\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in accepted_cleaned.select_dtypes('O').columns:\n",
    "    try:\n",
    "        current_table = pd.pivot_table(accepted_cleaned, values='loan_amnt', index=col, columns='loan_status', aggfunc='count')\n",
    "        sns.heatmap(current_table)\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot of object\n",
    "for col in accepted_cleaned.select_dtypes('float').columns:\n",
    "    sns.boxplot(y=col, x='loan_status',  data=accepted_cleaned)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "a quick run from multipple models to select the parameter that influence the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_cleaned['term'] = accepted_cleaned['term'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((565167, 74), (565167,), (1695501, 74), (1695501,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split and check\n",
    "X_train, X_test, y_train, y_test= train_test_split(accepted_cleaned.drop(columns='loan_status'), accepted_cleaned['loan_status'], test_size=0.75, random_state=42)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting and Pipeline build\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ColumnTransform = ColumnTransformer(transformers=[\n",
    "    ('numeric', StandardScaler(), X_train.select_dtypes(include='number').columns.tolist()),\n",
    "    ('categorical', OneHotEncoder(drop='first'), X_train.select_dtypes(include='category').columns.tolist())\n",
    "])\n",
    "Steps = [('pre_processing', ColumnTransform), ('RF', RandomForestClassifier(n_estimators=100, max_depth=4))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_C = Pipeline(steps=Steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('pre_processing',\n",
       "                 ColumnTransformer(transformers=[('numeric', StandardScaler(),\n",
       "                                                  ['loan_amnt', 'int_rate',\n",
       "                                                   'installment', 'annual_inc',\n",
       "                                                   'dti', 'delinq_2yrs',\n",
       "                                                   'fico_range_low',\n",
       "                                                   'fico_range_high',\n",
       "                                                   'inq_last_6mths', 'open_acc',\n",
       "                                                   'pub_rec', 'revol_bal',\n",
       "                                                   'revol_util', 'total_acc',\n",
       "                                                   'out_prncp', 'total_pymnt',\n",
       "                                                   'total_pymnt_inv',\n",
       "                                                   'total_rec_prncp',\n",
       "                                                   'total_rec_int',\n",
       "                                                   'total_rec_late_fee',\n",
       "                                                   'recoveries',\n",
       "                                                   'collection_recovery_fee',\n",
       "                                                   'last_pymnt_amnt',\n",
       "                                                   'last_fico_range_high',\n",
       "                                                   'last_fico_range_low',\n",
       "                                                   'collections_12_mths_ex_med',\n",
       "                                                   'acc_now_delinq',\n",
       "                                                   'tot_coll_amt',\n",
       "                                                   'tot_cur_bal',\n",
       "                                                   'total_rev_hi_lim', ...]),\n",
       "                                                 ('categorical',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  [])])),\n",
       "                ('RF', RandomForestClassifier(max_depth=4))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_C.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0', '0', '0', ..., '0', '0', '0'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_C.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=Pipeline(steps=[('pre_processing',\n",
       "                                           ColumnTransformer(transformers=[('numeric',\n",
       "                                                                            StandardScaler(),\n",
       "                                                                            ['loan_amnt',\n",
       "                                                                             'int_rate',\n",
       "                                                                             'installment',\n",
       "                                                                             'annual_inc',\n",
       "                                                                             'dti',\n",
       "                                                                             'delinq_2yrs',\n",
       "                                                                             'fico_range_low',\n",
       "                                                                             'fico_range_high',\n",
       "                                                                             'inq_last_6mths',\n",
       "                                                                             'open_acc',\n",
       "                                                                             'pub_rec',\n",
       "                                                                             'revol_bal',\n",
       "                                                                             'revol_util',\n",
       "                                                                             'total_acc',\n",
       "                                                                             'out_prncp',\n",
       "                                                                             'total_pymnt',\n",
       "                                                                             'total_pymnt_inv',\n",
       "                                                                             'tota...cp',\n",
       "                                                                             'total_rec_int',\n",
       "                                                                             'total_rec_late_fee',\n",
       "                                                                             'recoveries',\n",
       "                                                                             'collection_recovery_fee',\n",
       "                                                                             'last_pymnt_amnt',\n",
       "                                                                             'last_fico_range_high',\n",
       "                                                                             'last_fico_range_low',\n",
       "                                                                             'collections_12_mths_ex_med',\n",
       "                                                                             'acc_now_delinq',\n",
       "                                                                             'tot_coll_amt',\n",
       "                                                                             'tot_cur_bal',\n",
       "                                                                             'total_rev_hi_lim', ...]),\n",
       "                                                                           ('categorical',\n",
       "                                                                            OneHotEncoder(drop='first'),\n",
       "                                                                            [])])),\n",
       "                                          ('RF',\n",
       "                                           RandomForestClassifier(max_depth=4))]),\n",
       "                prefit=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SelectFromModel(RF_C, prefit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'RF__n_estimators': 50, 'RF__criterion':['gini'], 'RF__max_depth':4 }"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
